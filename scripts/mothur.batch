## Mothur batch file

# Tell mothur where to look for your input files (fastq and stability)
# Tell mothur where to store the output files
# Give mothur an alternative directory called tempdefault where it can look for files
# that are not in your input directory. These files are typically the silva database files, 
# which are stored on Vincent's scratch flux location listed below. If you are running 
# this script locally, you will need to change the path. 
set.dir(input=/scratch/lsa_fluxm/michberr/HABS)
set.dir(output=/scratch/lsa_fluxm/michberr/HABS)
set.dir(tempdefault=/scratch/lsa_fluxm/vdenef/Databases/ssu_rRNA/Mothur/)

# Set processors based on the number of samples you have and whether you're using flux or fluxm. 
make.contigs(file=habs.files, processors=30)
summary.seqs(fasta=current)

# Remove sequences with ambiguous bases and sequences that are not between 240-275 bp
screen.seqs(fasta=current, group=current, summary=current, maxambig=0, maxlength=275, minlength=240, maxhomop=8)
summary.seqs(fasta=current)

# It would take forever to align every sequence, so we find just the unique ones
unique.seqs(fasta=current)
count.seqs(name=current, group=current)

# Align sequences to the v4 region of the silva database
align.seqs(fasta=current, reference=silva.seed_v119.pcr.v4.unique.align)
screen.seqs(fasta=current, count=current, start=1968, end=11550)
summary.seqs(count=current)

# Filter sequences to remove overhangs at both ends and gaps
# After this we rerun unique.seqs because we might have created
# some new redundancies from the filtering
filter.seqs(fasta=current, vertical=T, trump=.)
unique.seqs(fasta=current, count=current)

# Precluster sequences allowing for up to 2 differences between sequences.
# The goal of this step is to eliminate sequences with errors due to sequencing technology
# by merging them with very similar sequences
pre.cluster(fasta=current, count=current, diffs=2)

# Search for chimeras and remove them
chimera.uchime(fasta=current, count=current, dereplicate=t)
remove.seqs(fasta=current, accnos=current)
summary.seqs(count=current)

# Classify sequences with a bayesian classifier using the silva database
classify.seqs(fasta=current, count=current, reference=silva.nr_v119.pcr.v4.align, taxonomy=silva.nr_v119.tax, cutoff=60)

# Remove things which are classified as Chloroplast, Mitochondria, unknown, or Eukaryota
remove.lineage(fasta=current, count=current, taxonomy=current, taxon=Chloroplast-Mitochondria-unknown-Eukaryota)
summary.seqs(count=current)

# Remove groups such as mock communities that you won't use for further analysis
remove.groups(count=current, fasta=current, taxonomy=current, groups=Mock1-Mock2)
summary.seqs(count=current)

# Cluster sequences into OTUs. To save memory/time we first split sequences by taxlevel 4 (order) and 
# then cluster from there. Read mothur wiki for more info. 
cluster.split(fasta=current, count=current, taxonomy=current, splitmethod=classify, taxlevel=4, cutoff=0.15)

# Determine how many sequences are in each OTU, using a .03 similarity cutoff 
make.shared(list=current, count=current, label=0.03)

# Generate a consensus taxonomy for each OTU
classify.otu(list=current, count=current, taxonomy=current, label=0.03)

